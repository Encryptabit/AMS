---
phase: 02-pipeline-analysis
plan: 02
type: execute
---

<objective>
Document the data transformations and intermediate artifacts produced at each pipeline stage, including input/output types and file artifacts.

Purpose: Understand what data flows between pipeline stages and what files are produced.
Output: DATA-FLOW.md documenting input/output types per stage and ARTIFACTS.md cataloguing all intermediate files.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Previous plan context:**
@.planning/phases/02-pipeline-analysis/02-01-SUMMARY.md

**Phase 1 Discovery findings:**
@.planning/phases/01-discovery/CALLGRAPH-INSIGHTS.md
@.planning/phases/01-discovery/FILE-INVENTORY.md

**Key source files for data types:**
@host/Ams.Core/Models/
@host/Ams.Core/Runtime/ChapterContext.cs
@host/Ams.Core/Runtime/BookContext.cs

**From CLAUDE.md - known artifacts:**
- {chapter}.asr.json - ASR token timings
- {chapter}.align.anchors.json - Anchor sync points
- {chapter}.align.tx.json - Transcript index
- {chapter}.align.hydrate.json - Hydrated transcript
- {chapter}.TextGrid - MFA timing output

**Prior decisions affecting this phase:**
- Context hierarchy manages all runtime state (Phase 1)
- ChapterContext.Save is heavily depended upon (6+ callers)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Trace data transformations through pipeline stages</name>
  <files>.planning/phases/02-pipeline-analysis/DATA-FLOW.md</files>
  <action>
    For each pipeline stage (ASR → Alignment → MFA → Merge), document:
    1. Input data types (what types/objects are consumed)
    2. Output data types (what types/objects are produced)
    3. Transformation logic (how input becomes output)
    4. Model classes used (e.g., AsrResponse, AnchorResult, Transcript)

    Read the command ExecuteAsync methods and trace data flow.

    Create DATA-FLOW.md with:
    - Per-stage input/output table
    - Data type definitions (key fields)
    - Transformation summary
    - Mermaid data flow diagram
  </action>
  <verify>DATA-FLOW.md exists with per-stage input/output documentation</verify>
  <done>All pipeline stages documented with input/output types and transformations</done>
</task>

<task type="auto">
  <name>Task 2: Document intermediate artifacts produced</name>
  <files>.planning/phases/02-pipeline-analysis/ARTIFACTS.md</files>
  <action>
    Catalogue all files produced by the pipeline:
    1. List every JSON file written (name pattern, content structure)
    2. List every audio file produced (WAV, treated copies)
    3. List every MFA artifact (TextGrid, lab files, dictionaries)
    4. Document when each artifact is created (which stage)
    5. Document what each artifact contains (schema/structure)

    Search for file writes in ChapterContext and command implementations.

    Create ARTIFACTS.md with:
    - Complete artifact inventory table
    - Per-stage artifact production list
    - File naming conventions
    - Sample content structure for key artifacts
  </action>
  <verify>ARTIFACTS.md exists with complete inventory of all produced files</verify>
  <done>All intermediate artifacts catalogued with structure and timing</done>
</task>

<task type="auto">
  <name>Task 3: Map ChapterContext state transitions</name>
  <files>.planning/phases/02-pipeline-analysis/DATA-FLOW.md</files>
  <action>
    Document how ChapterContext state changes through the pipeline:
    1. What properties are set at each stage
    2. What constitutes a "complete" chapter state
    3. How Save() persists state to disk
    4. What triggers state transitions

    Read ChapterContext.cs and trace property mutations.

    Add to DATA-FLOW.md:
    - ChapterContext state machine diagram
    - Property mutation timeline
    - Persistence triggers
  </action>
  <verify>ChapterContext state transitions documented in DATA-FLOW.md</verify>
  <done>State machine documented showing all context state transitions</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] DATA-FLOW.md exists with input/output documentation per stage
- [ ] ARTIFACTS.md exists with complete artifact inventory
- [ ] All JSON artifacts documented with structure
- [ ] All audio/MFA artifacts documented
- [ ] ChapterContext state transitions mapped
- [ ] Data flow diagram created
</verification>

<success_criteria>
- Input/output types documented for all pipeline stages
- All intermediate artifacts catalogued with naming conventions
- ChapterContext state transitions understood
- Data flow diagram shows complete transformation chain
</success_criteria>

<output>
After completion, create `.planning/phases/02-pipeline-analysis/02-02-SUMMARY.md`:

# Phase 2 Plan 2: Data Flow & Artifacts Summary

**[Substantive one-liner about data transformations]**

## Performance
- Duration: X min
- Tasks: 3

## Accomplishments
- [Key findings about data flow]

## Files Created
- DATA-FLOW.md - [size]
- ARTIFACTS.md - [size]

## Key Findings
- [Data types used]
- [Artifacts produced]
- [State transitions]

## Next Step
Ready for 02-03-PLAN.md (Indexing Clarification)
</output>
